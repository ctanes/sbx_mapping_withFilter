# -*- mode: Snakemake -*-

from sunbeamlib import samtools
import pysam
import re

TARGET_MAPPING_FILTER = [
    expand(
        str(MAPPING_FP/"filtered"/"{genome}"/"{sample}.bam.bai"),
        genome=GenomeSegments.keys(), sample=Samples.keys()),
    expand(
        str(MAPPING_FP/"filtered"/"{genome}"/"coverage_filtered.csv"),
        genome=GenomeSegments.keys()),
    expand(
        str(MAPPING_FP/"filtered"/"{genome}"/"numReads.csv"),
        genome=GenomeSegments.keys()),
    expand(
        str(MAPPING_FP/"{genome}"/"numReads.csv"),
        genome=GenomeSegments.keys()),
    expand(
        str(MAPPING_FP/'filtered'/'{genome}'/'sliding_coverage.csv'),
        genome=GenomeSegments.keys()),
    expand(
        str(MAPPING_FP/'{genome}'/'sliding_coverage.csv'),
        genome=GenomeSegments.keys())
]

def filter_bam_alignments(bam_in_fp, bam_out_fp, percIdentity, alnLen):
    """                                              
    Filter the alignments in the bam file with the defined percent identity
    and alingment length thresholds.
    bam_in_fp:BAM file name to filer
    bam_out_fp:BAM file name to output
    percIdentity:percent identity threshold (out of 1)
    alnLen:alignment length threshold
    """
    f_in = pysam.AlignmentFile(bam_in_fp)
    with pysam.AlignmentFile(bam_out_fp, "wb", template=f_in) as out_file:
        for item in f_in:
            if(item.has_tag("MD")):
                mdstr = item.get_tag("MD")
                mdSub = re.sub(r'([\\^]*[ACGT]+)[0]*', ' \\1 ', mdstr)
                mdSplit = re.split('[ ]+', mdSub)
                nums = [int(i) for i in mdSplit if i.isdigit()]
                letters = [i for i in mdSplit if not i.isdigit()]
                letters = re.sub('[^ATCG]', '', "".join(letters))
                
                alnLen_seq = sum(nums) + len(letters)
                percIdentity_seq = sum(nums) / alnLen_seq
                
                if (alnLen_seq>alnLen and percIdentity_seq>percIdentity):
                    out_file.write(item)
    f_in.close()


def sliding_window_coverage(genome, bamfile, sample, output_fp, N, sampling):

    output_rows = []
    args = ["samtools", "depth", "-aa", bamfile]
    p = subprocess.Popen(args, stdout=subprocess.PIPE, universal_newlines=True)
    # Organize into a list of depths for each segment, streaming in text
    reader = csv.reader(p.stdout, delimiter='\t')
    data = {}
    for row in reader:
    	if not data.get(row[0]):
           data[row[0]] = []
    	data[row[0]].append(int(row[2]))

    fields = ['Genome', 'Segment', 'Sample', 'Location', 'Average']
    with open(output_fp, 'w') as f:
        writer = csv.writer(f)
    	writer.writerow(fields)
    	for segment in data.keys():
            if len(data[segment]) > sampling:
               moving_avg = numpy.convolve(data[segment], numpy.ones((N,))/N, mode='full')
               for i,x in enumerate(moving_avg):
                   if (i%sampling == 0): 
                       writer.writerow([genome, segment, sample, i, x])

rule samtools_get_sliding_coverage:
    input:
        str(MAPPING_FP/'{genome}'/'{sample}.bam')
    output:
        str(MAPPING_FP/'intermediates'/'{genome}'/'{sample}_sliding_coverage.csv')
    params:
        window_size = Cfg['sbx_mapping_withFilter']['window_size'],
        sampling = Cfg['sbx_mapping_withFilter']['sampling']
    run:
        sliding_window_coverage(wildcards.genome, input[0], wildcards.sample, output[0], params.window_size, params.sampling)

def _sliding_coverage_csvs(w):
    pattern = str(MAPPING_FP/'intermediates'/w.genome/'{sample}_sliding_coverage.csv')
    paths = sorted(expand(pattern, sample=Samples.keys()))
    return(paths)

rule samtools_summarize_sliding_coverage:
    input:
        _sliding_coverage_csvs
    output:
        str(MAPPING_FP/'{genome}'/'sliding_coverage.csv')
    shell: "(head -n 1 {input[0]}; tail -q -n +2 {input}) > {output}"


rule all_mapping_withFilter:
    input: TARGET_MAPPING_FILTER

rule filter_aln_quality:
    input:
        str(MAPPING_FP/'{genome}'/'{sample}.bam')
    output:
        str(MAPPING_FP/'filtered'/'{genome}'/'{sample}.bam')
    params:
        alnLen=Cfg['sbx_mapping_withFilter']['alnLen'],
        percIdentity=Cfg['sbx_mapping_withFilter']['percIdentity']
    run:
        print(input)
        filter_bam_alignments(
            input[0], output[0], params.percIdentity, params.alnLen)

#rule samtools_index_filtered:
#    input: str(MAPPING_FP/'filtered'/'{genome}'/'{sample}.bam')
#    output: str(MAPPING_FP/'filtered'/'{genome}'/'{sample}.bam.bai')
#    shell: "samtools index {input} {output}"

rule samtools_get_coverage_filtered:
    input:
        in_bam=str(MAPPING_FP/'filtered'/'{genome}'/'{sample}.bam'),
	in_bai=str(MAPPING_FP/'filtered'/'{genome}'/'{sample}.bam.bai')
    output:
        str(MAPPING_FP/'filtered'/'intermediates'/'{genome}'/'{sample}.csv')
    run:
        samtools.get_coverage_stats(
            wildcards.genome, input.in_bam, wildcards.sample, output[0])

def _sorted_filtered_csvs(w):
    pattern = str(MAPPING_FP/'filtered'/'intermediates'/w.genome/'{sample}.csv')
    paths = sorted(expand(pattern, sample=Samples.keys()))
    return(paths)

rule samtools_summarize_filtered_coverage:
    input: 
        _sorted_filtered_csvs
    output:
        str(MAPPING_FP/'filtered'/'{genome}'/'coverage_filtered.csv')
    shell: "(head -n 1 {input[0]}; tail -q -n +2 {input}) > {output}"
    
rule samtools_summarize_num_mapped_reads:
    input:
        str(MAPPING_FP/'{genome}'/'{sample}.bam')
    output:
        str(MAPPING_FP/'intermediates'/'{genome}'/'{sample}_numReads.csv')
    shell:
        """
        samtools idxstats {input} | (sed 's/^/{wildcards.sample}\t/') > {output}
        """

def _numReads(w):
    pattern = str(MAPPING_FP/'intermediates'/w.genome/'{sample}_numReads.csv')
    paths = sorted(expand(pattern, sample=Samples.keys()))
    return(paths)

rule samtools_summarize_numReads:
    input:
        _numReads
    output:
        str(MAPPING_FP/'{genome}'/'numReads.csv')
    shell: "(cat {input}) > {output}"